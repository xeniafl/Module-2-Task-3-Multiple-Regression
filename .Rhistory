Let's have a closer look at Product Type distribution. Indeed if we look at the boxplot distributions, Game console have huge volume, but that's skewed due to the distribution of the data:
```{r}
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot()
ggplot(existing_product_attributes2017, aes(x = x4StarReviews, y = Volume, colour = ProductType)) + geom_point()
ggplot(existing_product_attributes2017, aes(x = Volume, fill = ProductType)) + geom_histogram(colour = "black")
ggplot(existing_product_attributes2017, aes(x = Volume, fill = ProductType)) + geom_histogram(colour = "black")
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar()
```{r}
library(lattice)
library(caret)
set.seed(123)
inTrain <- createDataPartition(y = existing_product_attributes2017$Volume, p = .80, list = FALSE)
training <- existing_product_attributes2017[ inTrain,]
testing <- existing_product_attributes2017[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = existing_product_attributes2017$Volume, p = .80, list = FALSE)
training <- existing_product_attributes2017[ inTrain,]
testing <- existing_product_attributes2017[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf")
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing)
postResample(pred = prediction, obs = testing$Volume)
varimp(fit)
varImp(fit)
varImp(fit)
fit <- train(Volume ~ ., data = training, method = "rf")
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
View(existing_product_attributes2017)
View(dummyok)
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
postResample(pred = prediction, obs = testing$Volume)
set.seed(123)
inTrain <- createDataPartition(y = existing_product_attributes2017$Volume, p = .80, list = FALSE)
training <- existing_product_attributes2017[ inTrain,]
testing <- existing_product_attributes2017[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = existing_product_attributes2017$Volume, p = .80, list = FALSE)
training <- existing_product_attributes2017[ inTrain,]
testing <- existing_product_attributes2017[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
set.seed(123)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
library(readr)
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
library(readr)
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
## DUMMY VARS
```{r}
library(caret)
library(ggplot2)
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
library(corrplot)
corrplot(correlation_matrix)
library(caret)
library(ggplot2)
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
library(corrplot)
corrplot(correlation_matrix)
```{r}
library(party)
existing_product_attributes2017$x5StarReviews <- NULL
existing_product_attributes2017$ProductType <- as.factor(existing_product_attributes2017$ProductType)
DecisionTree <- ctree(Volume ~ ., data = existing_product_attributes2017, controls = ctree_control(maxdepth = 10))
plot(DecisionTree)
library(party)
existing_product_attributes2017$x5StarReviews <- NULL
existing_product_attributes2017$ProductType <- as.factor(existing_product_attributes2017$ProductType)
DecisionTree <- ctree(Volume ~ ., data = existing_product_attributes2017, controls = ctree_control(maxdepth = 10))
plot(DecisionTree)
This means that 4 star review, positive service review are by far the 2 variables impacting the most volume. It looks like product type (especially Game COnsole) could have en impact, but we are not sure. This is why we'll keep these 3 and remove the rest:
```{r}
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
Let's have a closer look at Product Type distribution. Indeed if we look at the boxplot distributions, Game console have huge volume, but that's skewed due to the distribution of the data:
```{r}
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot()
ggplot(existing_product_attributes2017, aes(x = x4StarReviews, y = Volume, colour = ProductType)) + geom_point()
ggplot(existing_product_attributes2017, aes(x = Volume, fill = ProductType)) + geom_histogram(colour = "black")
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar()
```{r}
library(lattice)
library(caret)
set.seed(123)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummy_existing$Volume, p = .80, list = FALSE)
training <- dummy_existing[ inTrain,]
testing <- dummy_existing[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
View(dummy_existing)
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
View(dummyok)
varImp(fit)
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
for (i in models) {
fit <- train(Volume ~ ., data = training, method = i, importance=T)
prediction <- predict(fit, testing)
hola <- postResample(pred = prediction, obs = testing$Volume)
tabla <- cbind(hola, tabla)
}
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
for (i in models) {
fit <- train(Volume ~ ., data = training, method = i, importance=T)
prediction <- predict(fit, testing)
hola <- postResample(pred = prediction, obs = testing$Volume)
resum <- cbind(hola, resum)
}
resum
colnames(resum) <-(models)
resum
library(ggplot2)
ggplot(resum, aes(x = ))
resum
library(ggplot2)
library(data.table)
resumok <- as.data.frame(melt(resum))
ggplot(resumok, aes(y = value, x = Var2)) + geom_col() + facet_wrap( ~ Var1, scale = "free")
library(readr)
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
library(readr)
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
library(readr)
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
## DUMMY VARS
```{r}
library(caret)
library(ggplot2)
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
library(corrplot)
corrplot(correlation_matrix)
library(caret)
library(ggplot2)
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
library(corrplot)
corrplot(correlation_matrix)
```{r}
library(party)
existing_product_attributes2017$x5StarReviews <- NULL
existing_product_attributes2017$ProductType <- as.factor(existing_product_attributes2017$ProductType)
DecisionTree <- ctree(Volume ~ ., data = existing_product_attributes2017, controls = ctree_control(maxdepth = 10))
plot(DecisionTree)
library(party)
existing_product_attributes2017$x5StarReviews <- NULL
existing_product_attributes2017$ProductType <- as.factor(existing_product_attributes2017$ProductType)
DecisionTree <- ctree(Volume ~ ., data = existing_product_attributes2017, controls = ctree_control(maxdepth = 10))
plot(DecisionTree)
This means that 4 star review, positive service review are by far the 2 variables impacting the most volume. It looks like product type (especially Game COnsole) could have en impact, but we are not sure. This is why we'll keep these 3 and remove the rest:
```{r}
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
Let's have a closer look at Product Type distribution. Indeed if we look at the boxplot distributions, Game console have huge volume, but that's skewed due to the distribution of the data:
```{r}
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot()
ggplot(existing_product_attributes2017, aes(x = x4StarReviews, y = Volume, colour = ProductType)) + geom_point()
ggplot(existing_product_attributes2017, aes(x = Volume, fill = ProductType)) + geom_histogram(colour = "black")
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar()
```{r}
library(lattice)
library(caret)
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(123)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
resum <- c()
for (i in models) {
fit <- train(Volume ~ ., data = training, method = i, importance=T)
prediction <- predict(fit, testing)
hola <- postResample(pred = prediction, obs = testing$Volume)
resum <- cbind(hola, resum)
}
resum
resum
```{r}
colnames(resum) <-(models)
resum
library(ggplot2)
library(data.table)
resumok <- as.data.frame(melt(resum))
ggplot(resumok, aes(y = value, x = Var2)) + geom_col() + facet_wrap( ~ Var1, scale = "free")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, error = FALSE)
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
set.seed(5)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(5)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(5)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
for (i in models) {
fit <- train(Volume ~ ., data = training, method = i, importance=T)
prediction <- predict(fit, testing)
hola <- postResample(pred = prediction, obs = testing$Volume)
resum <- cbind(hola, resum)
}
resum
colnames(resum) <-(models)
resum
library(ggplot2)
library(data.table)
resumok <- as.data.frame(melt(resum))
ggplot(resumok, aes(y = value, x = Var2)) + geom_col() + facet_wrap( ~ Var1, scale = "free")
set.seed(23)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
set.seed(23)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
```{r}
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
postResample(pred = prediction, obs = testing$Volume)
varImp(fit)
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
for (i in models) {
fit <- train(Volume ~ ., data = training, method = i, importance=T)
prediction <- predict(fit, testing)
hola <- postResample(pred = prediction, obs = testing$Volume)
resum <- cbind(hola, resum)
}
resum
colnames(resum) <-(models)
resum
library(ggplot2)
library(data.table)
resumok <- as.data.frame(melt(resum))
ggplot(resumok, aes(y = value, x = Var2)) + geom_col() + facet_wrap( ~ Var1, scale = "free")
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar()
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar()
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count()
View(existing_product_attributes2017)
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot()
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot()
Summary(existing_product_attributes2017)
summary(existing_product_attributes2017)
varImp(fit)
DecisionTree <- ctree(Volume ~ ., data = dummyok, controls = ctree_control(maxdepth = 10))
plot(DecisionTree)
View(new_product_attributes2017)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, error = FALSE, message = FALSE)
library(readr)
library(ggplot2)
library(caret)
library(corrplot)
library(party)
library(lattice)
library(data.table)
library(caret)
library(corrplot)
library(party)
library(lattice)
library(data.table)
```{r}
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
existing_product_attributes2017 <- read_csv("C:/Users/user/Downloads/existingproductattributes2017.csv")
existing_product_attributes2017$BestSellersRank <- NULL
new_product_attributes2017 <- read_csv("C:/Users/user/Downloads/newproductattributes2017.csv")
new_product_attributes2017$BestSellersRank <- NULL
### Data understanding & Pre processing
To tackle this task, our first step was to understand and pre process the data we were given, and as Danielle was asking, put special focus on assessing whether Product Type impacted sales volume or not.
#### Missing data
We can see that Best Seller rank has missing data, this is why we will dismiss this variable.
#### Categorical to binary data conversion
Once we have no missing data, we want to find correlations with the different variables, and to do so we will need to dummify our only categorical variable: product type. Once this is done, we can spot the following correlations:
```{r}
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
corrplot(correlation_matrix, tl.cex = 0.5)
dummy_existing1 <- dummyVars(" ~ .", data = existing_product_attributes2017)
dummy_existing <- data.frame(predict(dummy_existing1, newdata = existing_product_attributes2017))
correlation_matrix <- cor(dummy_existing)
corrplot(correlation_matrix, tl.cex = 0.5)
#### Feature selection
Thanks to this correlation matrix we can see that there are 6 variables that have a high correlation with volume:
1. 5 stars review
2. 4 stars review
3. 3 stars review
4. Positive service review
5. 2 stars review
6. Product Type Game Console
However, we can see also that 5 stars review has a 100% correlation with volume, which is impossible and must be by chance, so we can't use it. Also that 3 and 2 stars review are colinear with 4 stars review. This is why we will remove them and make sure we can use 4 stars review, Positive service review and Product Type Game Console.
```{r}
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
dummyok$ProductType <- as.factor(dummyok$ProductType)
dummyok <- subset(existing_product_attributes2017, select = c("ProductType", "Volume", "x4StarReviews", "PositiveServiceReview"))
dummyok$ProductType <- as.factor(dummyok$ProductType)
Out of these 3 remaining variables, we will inspect further the distribution of the variable with the weakest correlation, Product Type:
```{r}
DecisionTree <- ctree(Volume ~ ., data = dummyok, controls = ctree_control(maxdepth = 15))
plot(DecisionTree)
In this decision tree we can see that Product Type Game Console doesn't appear. Even if we run a random forest, the importance of Product Type Game Console is still low:
```{r}
set.seed(58)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
prediction <- predict(fit, testing)
varImp(fit)
set.seed(58)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
fit <- train(Volume ~ ., data = training, method = "rf", importance=T)
Let's have a closer look at Product Type distribution. Indeed if we look at the boxplot distributions, Game console have huge volume, but that's skewed due to the distribution of the data:
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(existing_product_attributes2017, aes(x= ProductType, y = Volume)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
We can see that Game Console has only 2 data points, which is why we can't rely on it. Furthermore, if we look at all product types and volume, we can find no relationship:
```{r}
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
ggplot(existing_product_attributes2017, aes(x = x4StarReviews, y = Volume, colour = ProductType)) + geom_point()
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
ggplot(existing_product_attributes2017, aes(x = x4StarReviews, y = Volume, colour = ProductType)) + geom_point()
Plus, product type in the existing product sample and in the new product sample are distributed differently:
```{r}
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(existing_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(new_product_attributes2017, aes(x= ProductType,)) + geom_bar() + stat_count() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
This is why we decided not to use Product Type at all and use only 4 stars reviews and positive service review.
```{r}
dummyok <- subset(existing_product_attributes2017, select = c("Volume", "x4StarReviews", "PositiveServiceReview"))
dummyok <- subset(existing_product_attributes2017, select = c("Volume", "x4StarReviews", "PositiveServiceReview"))
## Modeling
```{r}
for (i in 1:10) {
set.seed(i)
inTrain <- createDataPartition(y = dummyok$Volume, p = .80, list = FALSE)
training <- dummyok[ inTrain,]
testing <- dummyok[-inTrain,]
models <- c("svmLinear", "knn", "rf", "lm")
resum <- c()
resumseed <- c()
for (j in models) {
fit <- train(Volume ~ ., data = training, method = j,)
predictedvolume <- predict(fit, testing)
hola <- postResample(pred = predictedvolume, obs = testing$Volume)
resum <- cbind(hola, resum)
}
colnames(resum) <-(models)
resumseed <- rbind(resum, resumseed)
}
```{r}
resumseedok <- as.data.frame(melt(resumseed))
SVM <- subset.data.frame(resumseedok, resumseedok$Var2 == "svmLinear")
KNN <- subset.data.frame(resumseedok, resumseedok$Var2 == "knn")
RF <- subset.data.frame(resumseedok, resumseedok$Var2 == "rf")
LM <- subset.data.frame(resumseedok, resumseedok$Var2 == "lm")
resumerrormetrics <- cbind(tapply(SVM$value, SVM$Var1, mean), tapply(KNN$value, KNN$Var1, mean), tapply(RF$value, RF$Var1, mean), tapply(LM$value, LM$Var1, mean))
colnames(resumerrormetrics) <-(models)
resumerrormetrics
resumerrormetrics
```{r}
fit <- train(Volume ~ ., data = training, method = "knn", importance=T)
fit <- train(Volume ~ ., data = training, method = "knn", importance=T)
predictedvolume <- round(predict(fit, new_product_attributes2017), digits = 0)
newproductw_prediction <- cbind(predictedvolume, new_product_attributes2017)
newproductw_prediction
ggplot(newproductw_prediction, aes(x = predictedvolume, fill = ProductType)) + geom_histogram()
write.csv(newproductw_prediction, file="newproductw_prediction.csv", row.names = TRUE)
write.csv(newproductw_prediction, file="newproductw_prediction.csv", row.names = TRUE)
predictiongraph<- read_csv("C:/Users/user/Documents/multiple regression/newproductw_prediction.csv")
ggplot(predictiongraph, aes(y = predictedvolume, x = ProductType, fill = ProductType)) + geom_col() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
predictiongraph<- read_csv("C:/Users/user/Documents/multiple regression/newproductw_prediction.csv")
ggplot(predictiongraph, aes(y = predictedvolume, x = ProductType, fill = ProductType)) + geom_col() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
summary(aov(Volume ~ ProductType, data = existing_product_attributes2017))
